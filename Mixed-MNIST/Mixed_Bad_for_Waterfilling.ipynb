{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "from baseline import Baseline\n",
    "from system_t import System_T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mixed-MNIST dataset from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra_keras_datasets import emnist\n",
    "\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = emnist.load_data(type='balanced')\n",
    "mnist_train_images = mnist_train_images.reshape((-1, 28, 28, 1)) / 255.0\n",
    "mnist_test_images = mnist_test_images.reshape((-1, 28, 28, 1)) / 255.0\n",
    "\n",
    "idx = mnist_train_labels <= 9\n",
    "mnist_train_images = mnist_train_images[idx]\n",
    "mnist_train_labels = mnist_train_labels[idx]\n",
    "\n",
    "fashion = tf.keras.datasets.fashion_mnist\n",
    "(fashion_train_images,fashion_train_labels), (fashion_test_images, fashion_test_labels) = fashion.load_data()\n",
    "\n",
    "fashion_train_labels = fashion_train_labels + 10\n",
    "fashion_test_labels = fashion_test_labels + 10\n",
    "fashion_train_images = fashion_train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "fashion_test_images = fashion_test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "train_images = np.concatenate((mnist_train_images, fashion_train_images), axis=0)\n",
    "train_labels = np.concatenate((mnist_train_labels, fashion_train_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad for Water filling: a pathological setting for Water filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of slices : 20\n",
      "(4500, 28, 28, 1) (4500, 20) 20\n"
     ]
    }
   ],
   "source": [
    "def shuffle(data, label):\n",
    "    shuffle = np.arange(len(data))\n",
    "    np.random.shuffle(shuffle)\n",
    "    data = data[shuffle]\n",
    "    label = label[shuffle]\n",
    "    return data, label\n",
    "\n",
    "num_class = len(np.unique(train_labels))\n",
    "print(\"Number of slices : %d\" % num_class)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(train_labels)\n",
    "mixed_data = (train_images, y_train_one_hot)\n",
    "\n",
    "initial_data_array = []\n",
    "val_data_dict = []\n",
    "add_data_dict = []\n",
    "    \n",
    "val_data_num = 500\n",
    "\n",
    "for i in range(num_class):\n",
    "    if i < 10:\n",
    "        data_num = 150\n",
    "    else:\n",
    "        data_num = 300\n",
    "    \n",
    "    initial_data_array.append(data_num)\n",
    "    idx = np.argmax(mixed_data[1], axis=1) == i\n",
    "\n",
    "    val_data_dict.append((mixed_data[0][idx][data_num:data_num+val_data_num], mixed_data[1][idx][data_num:data_num+val_data_num]))\n",
    "    add_data_dict.append((mixed_data[0][idx][data_num+val_data_num:], mixed_data[1][idx][data_num+val_data_num:]))\n",
    "\n",
    "    if i == 0:\n",
    "        train_data = mixed_data[0][idx][:data_num]\n",
    "        train_label = mixed_data[1][idx][:data_num]\n",
    "        val_data = mixed_data[0][idx][data_num:data_num+val_data_num]\n",
    "        val_label = mixed_data[1][idx][data_num:data_num+val_data_num]\n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, mixed_data[0][idx][:data_num]), axis=0)\n",
    "        train_label = np.concatenate((train_label, mixed_data[1][idx][:data_num]), axis=0) \n",
    "        val_data = np.concatenate((val_data, mixed_data[0][idx][data_num:data_num+val_data_num]), axis=0)\n",
    "        val_label = np.concatenate((val_label, mixed_data[1][idx][data_num:data_num+val_data_num]), axis=0)   \n",
    "    \n",
    "train_data, train_label = shuffle(train_data, train_label)\n",
    "print(train_data.shape, train_label.shape, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: Digit 0, Initial size: 150\n",
      "Slice: Digit 1, Initial size: 150\n",
      "Slice: Digit 2, Initial size: 150\n",
      "Slice: Digit 3, Initial size: 150\n",
      "Slice: Digit 4, Initial size: 150\n",
      "Slice: Digit 5, Initial size: 150\n",
      "Slice: Digit 6, Initial size: 150\n",
      "Slice: Digit 7, Initial size: 150\n",
      "Slice: Digit 8, Initial size: 150\n",
      "Slice: Digit 9, Initial size: 150\n",
      "Slice: T-shirt/top, Initial size: 300\n",
      "Slice: Trouser, Initial size: 300\n",
      "Slice: Pullover, Initial size: 300\n",
      "Slice: Dress, Initial size: 300\n",
      "Slice: Coat, Initial size: 300\n",
      "Slice: Sandal, Initial size: 300\n",
      "Slice: Shirt, Initial size: 300\n",
      "Slice: Sneaker, Initial size: 300\n",
      "Slice: Bag, Initial size: 300\n",
      "Slice: Ankle boot, Initial size: 300\n"
     ]
    }
   ],
   "source": [
    "slice_desc = []\n",
    "# Mixed mnist\n",
    "a = [\"Digit 0\", \"Digit 1\",\"Digit 2\",\"Digit 3\",\"Digit 4\",\"Digit 5\",\"Digit 6\",\"Digit 7\",\"Digit 8\",\"Digit 9\",\n",
    "   \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "for i in range(num_class):\n",
    "    slice_desc.append('Slice: %s' % (a[i]))\n",
    "    print('Slice: %s, Initial size: %s' % (a[i], initial_data_array[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original ( with no data acquisition ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Uniform, Budget: 0\n",
      "======= Collect Data =======\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "======= Performance =======\n",
      "Loss: 0.26588 (0.00327), Average EER: 0.16637 (0.00534), Max EER: 0.65057 (0.10295)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_func = [1] * num_class\n",
    "lr = 0.0005\n",
    "\n",
    "ori = Baseline((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict, method='Uniform')\n",
    "ori.performance(budget=0, cost_func=cost_func, num_iter=10, batch_size=32, lr=lr, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System T Demo on Mixed-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 3000 budget, lambda=0.1, \"Moderate\" strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Collect Data =======\n",
      "[ 11  13  44  25  45  58  12  40  49  50  90   0  45  36 148   5 183  11\n",
      "   0   0]\n",
      "Total Cost: 865, Remaining Budget: 2135\n",
      "======= Collect Data =======\n",
      "[  5  16  96  55 117  62   7 115 150 123 219   0 425  90 169   0 347   0\n",
      "  12   2]\n",
      "Total Cost: 2010, Remaining Budget: 125\n",
      "======= Collect Data =======\n",
      "[ 0  0  0  1  0  0  8  0  3  0  0  0  0 61  0 18 35  0  0  0]\n",
      "Total Cost: 126, Remaining Budget: -1\n",
      "\n",
      "======= Performance =======\n",
      "[ 16.  29. 140.  81. 162. 120.  27. 155. 202. 173. 309.   0. 470. 187.\n",
      " 317.  23. 565.  11.  12.   2.]\n",
      "Number of iteration: 3\n",
      "Strategy: Moderate, C: 0.1, Budget: 3000\n",
      "Loss: 0.21949 (0.00364), Average EER: 0.13280 (0.00605), Max EER: 0.49166 (0.08976)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget = 3000\n",
    "method = 'Moderate'\n",
    "\n",
    "st = System_T((train_data, train_label), (val_data, val_label), val_data_dict, initial_data_array, num_class, add_data_dict)\n",
    "st.selective_collect(budget=budget, k=10, batch_size=32, lr = lr, epochs=2000, cost_func=cost_func, \n",
    "                 Lambda=0.1, num_iter=5, slice_desc=slice_desc, strategy=method, show_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Uniform, Budget: 3000\n",
      "======= Collect Data =======\n",
      "[150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150\n",
      " 150 150]\n",
      "======= Performance =======\n",
      "Loss: 0.22589 (0.00391), Average EER: 0.15657 (0.00619), Max EER: 0.59213 (0.05565)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget = 3000\n",
    "uni = Baseline((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict, method='Uniform')\n",
    "uni.performance(budget=budget, cost_func=cost_func, num_iter=10, batch_size=32, lr=lr, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Water filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Waterfilling, Budget: 3000\n",
      "======= Collect Data =======\n",
      "[225 225 225 225 225 225 225 225 225 225  75  75  75  75  75  75  75  75\n",
      "  75  75]\n",
      "======= Performance =======\n",
      "Loss: 0.22802 (0.00292), Average EER: 0.16671 (0.00477), Max EER: 0.68417 (0.07454)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget = 3000\n",
    "wf = Baseline((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict, method='Waterfilling')\n",
    "wf.performance(budget=budget, cost_func=cost_func, num_iter=10, batch_size=32, lr=lr, epochs=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
