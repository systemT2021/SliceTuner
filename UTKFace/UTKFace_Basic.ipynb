{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "from baseline import Baseline\n",
    "from system_t import System_T\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load UTKFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgViewer(file_path):\n",
    "    if type(img) == str:\n",
    "        img = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(img, interpolation='nearest')\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "file_name_list = os.listdir(\"/home/kihyun/system/utkface/dataset/UTKFace\")\n",
    "\n",
    "x_data = []\n",
    "age_array = []\n",
    "gender_array = []\n",
    "race_array = []\n",
    "\n",
    "for file_name in file_name_list:\n",
    "    token = file_name.split('_')\n",
    "    file_path = \"/home/kihyun/system/utkface/dataset/UTKFace/\" + file_name\n",
    "  \n",
    "    if len(token) == 4:\n",
    "        if int(token[0]) >= 10 and int(token[0]) < 90:\n",
    "            if int(token[2]) < 4:\n",
    "                img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (32, 32)) / 255.0\n",
    "                x_data.append(img)\n",
    "                age_array.append(int(token[0]))\n",
    "                gender_array.append(int(token[1]))\n",
    "                race_array.append(int(token[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([4910, 3951, 2244, 2111, 1070, 1399, 2035, 1446]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.array(x_data)\n",
    "age_array = np.array(age_array)\n",
    "gender_array = np.array(gender_array)\n",
    "race_array = np.array(race_array)\n",
    "\n",
    "slice_array = race_array*2 + gender_array\n",
    "\n",
    "np.unique(slice_array, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_x_data = []\n",
    "add_race_array = []\n",
    "add_slice_array = []\n",
    "race_num = 0\n",
    "for race in [\"whitemale\", \"whitefemale\", \"blackmale\", \"blackfemale\", \"asianmale\", \"asianfemale\", \"indianmale\", \"indianfemale\"]:\n",
    "    image_path = \"/home/di_lab/crop_image/%s/\" % race\n",
    "    file_name_list = os.listdir(image_path)\n",
    "    \n",
    "    for file_name in file_name_list:\n",
    "        file_path = image_path + file_name\n",
    "        img = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (32, 32)) / 255.0\n",
    "        add_x_data.append(img)\n",
    "        \n",
    "        add_race_array.append(race_num//2)\n",
    "        add_slice_array.append(race_num)\n",
    "    \n",
    "    race_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([1009, 1069, 1000, 1035,  892,  947,  846,  912]))\n",
      "(array([0, 1, 2, 3]), array([2078, 2035, 1839, 1758]))\n"
     ]
    }
   ],
   "source": [
    "add_x_data = np.array(add_x_data)\n",
    "add_race_array = np.array(add_race_array)\n",
    "add_slice_array = np.array(add_slice_array)\n",
    "\n",
    "print(np.unique(add_slice_array, return_counts=True))\n",
    "print(np.unique(add_race_array, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic setting: slices have the same amounts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of slices : 8, 4\n",
      "(4000, 32, 32, 3) (4000, 4) 8\n"
     ]
    }
   ],
   "source": [
    "def shuffle(data, label, race):\n",
    "    shuffle = np.arange(len(data))\n",
    "    np.random.shuffle(shuffle)\n",
    "    data = data[shuffle]\n",
    "    label = label[shuffle]\n",
    "    race = race[shuffle]\n",
    "    return data, label, race\n",
    "\n",
    "num_class = len(np.unique(slice_array))\n",
    "num_label = len(np.unique(race_array))\n",
    "print(\"Number of slices : %d, %d\" % (num_class, num_label))\n",
    "\n",
    "mixed_data = (x_data, to_categorical(race_array), to_categorical(slice_array))\n",
    "mturk_data = (add_x_data, to_categorical(add_race_array), to_categorical(add_slice_array))\n",
    "\n",
    "initial_data_array = []\n",
    "val_data_dict = []\n",
    "add_data_dict = []\n",
    "    \n",
    "val_data_num = 500\n",
    "\n",
    "for i in range(num_class):\n",
    "    data_num = 500\n",
    "    initial_data_array.append(data_num)\n",
    "    idx = np.argmax(mixed_data[2], axis=1) == i\n",
    "    idx_ = np.argmax(mturk_data[2], axis=1) == i\n",
    "    \n",
    "    val_data_dict.append((mixed_data[0][idx][data_num:data_num+val_data_num], mixed_data[1][idx][data_num:data_num+val_data_num], mixed_data[2][idx][data_num:data_num+val_data_num]))\n",
    "    add_data_dict.append((mturk_data[0][idx_], mturk_data[1][idx_], mturk_data[2][idx_]))\n",
    "\n",
    "    if i == 0:\n",
    "        train_data = mixed_data[0][idx][:data_num]\n",
    "        train_label = mixed_data[1][idx][:data_num]\n",
    "        train_race =  mixed_data[2][idx][:data_num]\n",
    "        \n",
    "        val_data = mixed_data[0][idx][data_num:data_num+val_data_num]\n",
    "        val_label = mixed_data[1][idx][data_num:data_num+val_data_num]\n",
    "        val_race = mixed_data[2][idx][data_num:data_num+val_data_num]\n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, mixed_data[0][idx][:data_num]), axis=0)\n",
    "        train_label = np.concatenate((train_label, mixed_data[1][idx][:data_num]), axis=0) \n",
    "        train_race = np.concatenate((train_race, mixed_data[2][idx][:data_num]), axis=0) \n",
    "        \n",
    "        val_data = np.concatenate((val_data, mixed_data[0][idx][data_num:data_num+val_data_num]), axis=0)\n",
    "        val_label = np.concatenate((val_label, mixed_data[1][idx][data_num:data_num+val_data_num]), axis=0)   \n",
    "        val_race = np.concatenate((val_race, mixed_data[2][idx][data_num:data_num+val_data_num]), axis=0)   \n",
    "    \n",
    "train_data, train_label, train_race = shuffle(train_data, train_label, train_race)\n",
    "print(train_data.shape, train_label.shape, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: White-Male, Initial size: 500\n",
      "Slice: White-Female, Initial size: 500\n",
      "Slice: Black-Male, Initial size: 500\n",
      "Slice: Black-Female, Initial size: 500\n",
      "Slice: Asian-Male, Initial size: 500\n",
      "Slice: Asian-Female, Initial size: 500\n",
      "Slice: Indian-Male, Initial size: 500\n",
      "Slice: Indian-Female, Initial size: 500\n"
     ]
    }
   ],
   "source": [
    "slice_desc = []\n",
    "a = [\"White-Male\", \"White-Female\", \"Black-Male\", \"Black-Female\", \"Asian-Male\", \"Asian-Female\", \"Indian-Male\", \"Indian-Female\"]\n",
    "\n",
    "\n",
    "for i in range(num_class):\n",
    "    slice_desc.append('Slice: %s' % (a[i]))\n",
    "    print('Slice: %s, Initial size: %s' % (a[i], initial_data_array[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original ( with no data acquisition )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Uniform, Budget: 0\n",
      "======= Collect Data =======\n",
      "[0 0 0 0 0 0 0 0]\n",
      "======= Performance =======\n",
      "Loss: 0.56167 (0.00584), Average EER: 0.09069 (0.01049), Max EER: 0.16540 (0.02290)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_func = [1] * num_class\n",
    "lr = 0.0001\n",
    "\n",
    "ori = Baseline((train_data, train_label, train_race), (val_data, val_label, val_race), val_data_dict, \n",
    "                initial_data_array, num_class, num_label, add_data_dict, method='Uniform')\n",
    "ori.performance(budget=0, cost_func=cost_func, num_iter=10, batch_size=32, lr=lr, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System T Demo on UTKFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 3000 budget, lambda=0.1, \"Moderate\" strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Collect Data =======\n",
      "[456 338 197 525 450 198 474 361]\n",
      "Total Cost: 2999, Remaining Budget: 1\n",
      "\n",
      "======= Performance =======\n",
      "[456. 338. 197. 525. 450. 198. 474. 361.]\n",
      "Number of iteration: 1\n",
      "Strategy: Moderate, C: 0.1, Budget: 3000\n",
      "Loss: 0.54677 (0.00847), Average EER: 0.07053 (0.01092), Max EER: 0.13685 (0.02185)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget = 3000\n",
    "method = 'Moderate'\n",
    "\n",
    "st = System_T((train_data, train_label, train_race), (val_data, val_label, val_race), val_data_dict, initial_data_array, num_class, num_label, add_data_dict)\n",
    "st.selective_collect(budget=budget, k=10, batch_size=32, lr = lr, epochs=2000, cost_func=cost_func, \n",
    "                 Lambda=0.1, num_iter=5, slice_desc=slice_desc, strategy=method, show_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Uniform ( = Water fiiling )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a basic setting, Uniform method is equivalent to Water filling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Uniform, Budget: 3000\n",
      "======= Collect Data =======\n",
      "[375 375 375 375 375 375 375 375]\n",
      "======= Performance =======\n",
      "Loss: 0.55422 (0.00955), Average EER: 0.08128 (0.01761), Max EER: 0.18255 (0.04550)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget = 3000\n",
    "uni = Baseline((train_data, train_label, train_race), (val_data, val_label, val_race), val_data_dict, \n",
    "                initial_data_array, num_class, num_label, add_data_dict, method='Uniform')\n",
    "uni.performance(budget=budget, cost_func=cost_func, num_iter=10, batch_size=32, lr=lr, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Loss | Avg.EER |\n",
    "|:---------------------:|:---------------------:|:---------------------:|\n",
    "| Original | 0.56167 (± 0.00292) | 0.09069 (± 0.00524) |\n",
    "| Uniform | 0.55422 (± 0.00477) | 0.08128 (± 0.00881) |\n",
    "| Water filling | 0.55422 (± 0.00477) | 0.08128 (± 0.00881) |\n",
    "| Moderate (ours) | 0.54677 (± 0.00424) | 0.07053 (± 0.00546) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
